{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e88f05c-ab31-4448-ad16-8c1d881c93eb",
   "metadata": {},
   "source": [
    "This is a tutorial for multi-ancestry fine-mapping using MultiSuSiE. You should be able to run this jupyter notebook interactively from the MultiSuSiE/examples directory or click on the .ipynb file on github to view it statically.\n",
    "\n",
    "In this tutorial, we'll do the following:\n",
    "- Simulate a quantitative phenotype using real HapMap3 genotypes for a very small region on chromosome 1 including three populations with distinct continental genetic ancestries, YRI (Yoruba in Ibada, Nigeria), CEU (Utah residents with Northern and Western European ancestry), and JPT (Japanese in Tokyo, Japan).\n",
    "- Generate summary statistics using the simulated quantitative phenotype and real genotypes.\n",
    "- Fine-map our example locus using the summary statistics and individual level data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f6403b-91d5-4894-beaf-001754845d46",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5473aedb-0668-4a65-b320-8198926fbc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import MultiSuSiE\n",
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90c83d0-1d19-4ad9-84a0-cae7557dccd4",
   "metadata": {},
   "source": [
    "# Load data and simulate a quantitative phenotype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7013ed00-0ef7-4ed4-98b4-29d03c4f38c9",
   "metadata": {},
   "source": [
    "For this tutorial, we'll use a small piece of chromosome 1 from 3 HapMap3 populations, YRI, CEU, and JPT. We can load the example data using the following code chunk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773e8082-ef2d-4a37-8693-d41113cb38f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_YRI = np.loadtxt('../example_data/geno_YRI.txt')\n",
    "geno_CEU = np.loadtxt('../example_data/geno_CEU.txt')\n",
    "geno_JPT = np.loadtxt('../example_data/geno_JPT.txt')\n",
    "geno_list = [geno_YRI, geno_CEU, geno_JPT]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30478e7c-9e05-4216-867a-b0c409c06305",
   "metadata": {},
   "source": [
    "We're going to pretend that we have three causal variants. The first variant has varying effect sizes across ancestries. The second has identical effect sizes across ancestries. The third only has an effect in YRI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf73393-b1c5-4405-b0cc-7f5f4ea5b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_YRI = np.zeros(40)\n",
    "beta_CEU = np.zeros(40)\n",
    "beta_JPT = np.zeros(40)\n",
    "beta_YRI[10]=.75\n",
    "beta_CEU[10]=1\n",
    "beta_JPT[10]=.5\n",
    "beta_YRI[3]=.5\n",
    "beta_CEU[3]=.5\n",
    "beta_JPT[3]=.5\n",
    "beta_YRI[38]=1\n",
    "beta_CEU[38]=0\n",
    "beta_JPT[38]=0\n",
    "beta_list = [beta_YRI, beta_CEU, beta_JPT]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49464263-938c-45dd-9f2c-33c1a1b27637",
   "metadata": {},
   "source": [
    "# Calculate summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c75d7e-4358-47aa-a625-4eb464f045fd",
   "metadata": {},
   "source": [
    "For this tutorial, we'll calculate summary statistics in Python, but you'll likely calculate your association summary statistics using Plink2 and calculate LD matrices using LDStore2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b545247-4053-4528-bb55-cc40ef371762",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(2)\n",
    "y_list = [geno.dot(beta) + rng.standard_normal(geno.shape[0]) for (geno, beta) in zip(geno_list, beta_list)]\n",
    "y_list = [y - np.mean(y) for y in y_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecee6edc-4c71-45fc-948b-3c8ea397b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTY_list = [geno.T.dot(y) for (geno, y) in zip(geno_list, y_list)]\n",
    "XTX_diagonal_list = [np.diagonal(geno.T.dot(geno)) for geno in geno_list]\n",
    "with np.errstate(divide='ignore',invalid='ignore'): # just to silence a divide by zero error\n",
    "    beta_hat_list = [XTY / XTX_diag for (XTY, XTX_diag) in zip(XTY_list, XTX_diagonal_list)]\n",
    "\n",
    "N_list = [geno.shape[0] for geno in geno_list]\n",
    "residuals_list = [np.expand_dims(y, 1) - (geno * beta) for (y, geno, beta) in zip(y_list, geno_list, beta_hat_list)]\n",
    "sum_of_squared_residuals_list = [np.sum(resid ** 2, axis = 0) for resid in residuals_list]\n",
    "se_list = [np.sqrt(ssr / ((N - 2) * XTX)) for (ssr, N, XTX) in zip(sum_of_squared_residuals_list, N_list, XTX_diagonal_list)]\n",
    "\n",
    "with np.errstate(divide='ignore',invalid='ignore'): # just to silence a divide by zero error\n",
    "    R_list = [np.corrcoef(geno, rowvar = False) for geno in geno_list]\n",
    "\n",
    "YTY_list = [y.dot(y) for y in y_list]\n",
    "varY_list = [np.var(y, ddof = 1) for y in y_list]\n",
    "\n",
    "z_list = [b/s for (b,s) in zip(beta_hat_list, se_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d505db-b5b9-4b0f-82ef-324e3c276638",
   "metadata": {},
   "source": [
    "# Summary statistic based fine-mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72821e29-3152-4aab-aad1-c8ec08b121de",
   "metadata": {},
   "source": [
    "To run summary-statistic based multi-ancestry fine-mapping, there are two potential sets of inputs for each population:\n",
    "1. GWAS variant effect sizes, GWAS variant standard errors, an LD matrix, the sample phenotype variance, and the GWAS sample size\n",
    "2. GWAS Z-scores, an LD matrix, and the GWAS sample size\n",
    "\n",
    "The first input set is preferrable because it allows us to keep genotypes and phenotypes on their original scale, allows automatic filtering of low minor allele count variants, and is validated in the MultiSuSiE manuscript. If you choose to use the second input set, it's very important to censor low minor allele count variants in the population that they have low minor allele count in. You can either zero out the corresponding entries in that population's Z-score array, and the corresponding rows and columns in that populations LD matrix, or provide `mac_list` or `maf_list` and let `multisusie_rss` do it for you. We'll demonstrate this below.\n",
    "\n",
    "In either case, the inputs should be formatted as lists of numpy arrays (for the GWAS variant effect sizes, GWAS variant standard errors, GWAS Z-scores and LD matrix) or lists of scalars (for the sample phenotype variance and GWAS sample size). Each list should have length equal to the number of populations. The summary statistics we calculated above are already in this format.\n",
    "\n",
    "To run MultiSuSiE using the first input set, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "281e82bd-e361-48d8-82fc-6685c6aba730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censored 14 variants in population 0 due to low population-specific MAC\n",
      "Censored 15 variants in population 1 due to low population-specific MAC\n",
      "Censored 16 variants in population 2 due to low population-specific MAC\n"
     ]
    }
   ],
   "source": [
    "ss_fit = MultiSuSiE.multisusie_rss(\n",
    "    b_list = beta_hat_list,\n",
    "    s_list = se_list,\n",
    "    R_list = R_list,\n",
    "    varY_list = varY_list,\n",
    "    rho = np.array([[1, 0.75, 0.75], [0.75, 1, 0.75], [0.75, 0.75, 1]]),\n",
    "    population_sizes = N_list,\n",
    "    L = 10,\n",
    "    scaled_prior_variance = 0.2,\n",
    "    low_memory_mode = False,\n",
    "    float_type = np.float64,\n",
    "    estimate_prior_variance = False,\n",
    "    single_population_mac_thresh = 10 # set this to 20 unless your sample size is tiny, like in this example\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d68e36be-3b16-412f-ad29-26a1c11001ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PIPs of the causal variants are 0.5410728598612075, 0.9999864235182215, and 0.4811589978787054\n"
     ]
    }
   ],
   "source": [
    "print(f'The PIPs of the causal variants are {ss_fit.pip[3]}, {ss_fit.pip[10]}, and {ss_fit.pip[38]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca09f5-d53a-44c6-913e-c24edd6f7635",
   "metadata": {},
   "source": [
    "By examining the `pip` attribute of the object returned by `MultiSuSiE`, we can see that we've correctly assigned very high PIP to the 11th and 39th variants, and moderate PIP to the 4th variant. These variants have true causal effects in our simulations. By examining the `sets` attribute, we can see that the causal variant with lower PIP has been placed in a 95% credible set with only two other variants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63bb81d-5d84-4625-8a2e-e76ba2b19d83",
   "metadata": {},
   "source": [
    "If we'd rather use the second input option (Z-scores, LD, and sample size) than the first, we have to remember to censor low minor allele count variants, or provide multisusie_rss with `maf_list` or `mac_list` so it can do the censoring. Typically a minor allele count threshold of 20 is used for this, but due to the very low sample size in this example we'll use 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d71b678-4629-4c7d-a96e-10387fa965e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censored 14 variants in population 0 due to low population-specific MAC\n",
      "Censored 15 variants in population 1 due to low population-specific MAC\n",
      "Censored 16 variants in population 2 due to low population-specific MAC\n"
     ]
    }
   ],
   "source": [
    "maf_YRI = np.loadtxt('../example_data/maf_YRI.txt')\n",
    "maf_CEU = np.loadtxt('../example_data/maf_CEU.txt')\n",
    "maf_JPT = np.loadtxt('../example_data/maf_JPT.txt')\n",
    "maf_list = [maf_YRI, maf_CEU, maf_JPT]\n",
    "ss_fit = MultiSuSiE.multisusie_rss(\n",
    "    z_list = z_list,\n",
    "    R_list = R_list,\n",
    "    rho = np.array([[1, 0.75, 0.75], [0.75, 1, 0.75], [0.75, 0.75, 1]]),\n",
    "    population_sizes = N_list,\n",
    "    L = 10,\n",
    "    scaled_prior_variance = 0.2,\n",
    "    low_memory_mode = False,\n",
    "    single_population_mac_thresh = 10,\n",
    "    maf_list = maf_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d698f024-dbc0-4d5e-9fe4-fe974823f41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PIPs of the causal variants are 0.46658849716186523, 0.9999762177467346, and 0.9698582291603088\n"
     ]
    }
   ],
   "source": [
    "print(f'The PIPs of the causal variants are {ss_fit.pip[3]}, {ss_fit.pip[10]}, and {ss_fit.pip[38]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba567f-7ab5-4ac7-b67d-06bc4382fc98",
   "metadata": {},
   "source": [
    "# Summary statistics vs individual level fine-mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f71f5-c432-45e2-b702-60f87e43f2b5",
   "metadata": {},
   "source": [
    "Next, we'll demonstrate that the individual and summary statistic based versions of MultiSuSiE give identical results. At the time when this tutorial was being written, some of the default parameters for `multisusie_rss` (the top-level summary-statistic based fine-mapping function) had not been implemented for `multisusie` (the top-level individual-level based fine-mapping function), so we'll have to use some non-default parameters to get the same results for both functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfbafd13-9b89-4c4f-8c53-26068152e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_fit = MultiSuSiE.multisusie_rss(\n",
    "    b_list = beta_hat_list,\n",
    "    s_list = se_list,\n",
    "    R_list = R_list,\n",
    "    varY_list = varY_list,\n",
    "    rho = np.array([[1, 0.75, 0.75], [0.75, 1, 0.75], [0.75, 0.75, 1]]),\n",
    "    population_sizes = N_list,\n",
    "    L = 10,\n",
    "    low_memory_mode = False,\n",
    "    recover_R = False,\n",
    "    float_type = np.float64,\n",
    "    single_population_mac_thresh = 0,\n",
    ")\n",
    "indiv_fit = MultiSuSiE.multisusie(\n",
    "    X_list = [g + 1 for g in geno_list],\n",
    "    Y_list = y_list,\n",
    "    rho = np.array([[1, 0.75, 0.75], [0.75, 1, 0.75], [0.75, 0.75, 1]]),\n",
    "    L = 10,\n",
    "    standardize = False,\n",
    "    intercept = False,\n",
    "    float_type = np.float64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94540bb7-1f9c-472a-b5b9-73bb55f5f5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here, we can see that the maximum difference in PIP between the two methods is  0.9999665882457524"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(\"Here, we can see that the maximum difference in PIP between the two methods is  {}\".format(np.max(np.abs(ss_fit.pip - indiv_fit.pip))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d14af7-c666-405b-85ae-181115a1ea5b",
   "metadata": {},
   "source": [
    "# Z-score vs individual level fine-mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70755b3-9e78-416e-9fe2-51c93b3e86af",
   "metadata": {},
   "source": [
    "If you choose to do z-score based fine-mapping, this is equivalent to doing individual level fine-mapping after standardizing the genotype and phenotype matrices. We can see this below. Here, we're not censoring low MAC variants which is not recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c2e0e9d-7264-4ba8-8d8d-02f3fe72cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.errstate(divide='ignore',invalid='ignore'):\n",
    "    geno_std_list = [geno / np.std(geno, axis = 0, ddof = 1) for geno in geno_list]\n",
    "y_std_list = [y / np.std(y, ddof = 1) for y in y_list]\n",
    "XTX_std_list = [geno.T.dot(geno) for geno in geno_std_list]\n",
    "XTY_std_list = [geno.T.dot(pheno) for (geno, pheno) in zip(geno_std_list, y_std_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88d33871-617d-4c04-9f65-06300e446eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_fit = MultiSuSiE.multisusie_rss(\n",
    "    z_list = z_list,\n",
    "    R_list = R_list,\n",
    "    varY_list = None,\n",
    "    rho = np.array([[1, 0.75, 0.75], [0.75, 1, 0.75], [0.75, 0.75, 1]]),\n",
    "    population_sizes = N_list,\n",
    "    L = 10,\n",
    "    low_memory_mode = False,\n",
    "    recover_R = False,\n",
    "    float_type = np.float64,\n",
    "    single_population_mac_thresh = 0,\n",
    ")\n",
    "indiv_fit = MultiSuSiE.multisusie(\n",
    "    X_list = [np.nan_to_num(geno, 0) for geno in geno_std_list],\n",
    "    Y_list = y_std_list,\n",
    "    rho = np.array([[1, 0.75, 0.75], [0.75, 1, 0.75], [0.75, 0.75, 1]]),\n",
    "    L = 10,\n",
    "    standardize = False,\n",
    "    intercept = False,\n",
    "    float_type = np.float64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18fd82e4-ae8c-4665-8461-4a82227a126a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here, we can see that the maximum difference in PIP between the two methods is  3.6637359812630166e-15"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(\"Here, we can see that the maximum difference in PIP between the two methods is  {}\".format(np.max(np.abs(ss_fit.pip - indiv_fit.pip))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
