{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e88f05c-ab31-4448-ad16-8c1d881c93eb",
   "metadata": {},
   "source": [
    "This is a tutorial for multi-ancestry fine-mapping using MultiSuSiE. For now, this tutorial focuses on summary statistic-based fine-mapping. In the future, this tutorial will be expanded to include individual-level fine-mapping, which is also supported by the MultiSuSiE software package. You should be able to run this jupyter notebook from the MultiSuSiE/examples directory or just following along with the pdf.\n",
    "\n",
    "In this tutorial, we'll do the following:\n",
    "- Simulate a quantitative phenotype using real HapMap3 genotypes for a very small region on chromosome 1 including three populations with distinct continental genetic ancestries, YRI (Yoruba in Ibada, Nigeria), CEU (Utah residents with Northern and Western European ancestry), and JPT (Japanese in Tokyo, Japan).\n",
    "- Generate summary statistics using the simulated quantitative phenotype and real genotypes.\n",
    "- Fine-map our example locus using the summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f6403b-91d5-4894-beaf-001754845d46",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5473aedb-0668-4a65-b320-8198926fbc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import MultiSuSiE\n",
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90c83d0-1d19-4ad9-84a0-cae7557dccd4",
   "metadata": {},
   "source": [
    "# Load data and simulate a quantitative phenotype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7013ed00-0ef7-4ed4-98b4-29d03c4f38c9",
   "metadata": {},
   "source": [
    "For this tutorial, we'll use a small piece of chromosome 1 from 3 HapMap3 populations, YRI, CEU, and JPT. We can load the example data using the following code chunk. \n",
    "\n",
    "We're going to pretend that we have three causal variants. The first variant has varying effect sizes across ancestries. The second has identical effect sizes across ancestries. The third only has an effect in YRI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773e8082-ef2d-4a37-8693-d41113cb38f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_YRI = np.loadtxt('../example_data/geno_YRI.txt')\n",
    "geno_CEU = np.loadtxt('../example_data/geno_CEU.txt')\n",
    "geno_JPT = np.loadtxt('../example_data/geno_JPT.txt')\n",
    "geno_list = [geno_CEU, geno_YRI, geno_JPT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf73393-b1c5-4405-b0cc-7f5f4ea5b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_YRI = np.zeros(40)\n",
    "beta_CEU = np.zeros(40)\n",
    "beta_JPT = np.zeros(40)\n",
    "beta_YRI[10]=.75\n",
    "beta_CEU[10]=1\n",
    "beta_JPT[10]=.5\n",
    "beta_YRI[3]=.5\n",
    "beta_CEU[3]=.5\n",
    "beta_JPT[3]=.5\n",
    "beta_YRI[38]=1\n",
    "beta_CEU[38]=0\n",
    "beta_JPT[38]=0\n",
    "beta_list = [beta_YRI, beta_CEU, beta_JPT]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49464263-938c-45dd-9f2c-33c1a1b27637",
   "metadata": {},
   "source": [
    "# Calculate summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c75d7e-4358-47aa-a625-4eb464f045fd",
   "metadata": {},
   "source": [
    "For this tutorial, we're going to calculate our summary statistics in Python, but you'll likely calculate your association summary statistics using Plink2 and calculate LD matrices using LDStore2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b545247-4053-4528-bb55-cc40ef371762",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1)\n",
    "y_list = [geno.dot(beta) + rng.standard_normal(geno.shape[0]) for (geno, beta) in zip(geno_list, beta_list)]\n",
    "y_list = [y - np.mean(y) for y in y_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecee6edc-4c71-45fc-948b-3c8ea397b589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/77/mk7r4vgs7w1_m2d24r01lhd40000gn/T/ipykernel_26877/4224691857.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  beta_hat_list = [XTY / XTX_diag for (XTY, XTX_diag) in zip(XTY_list, XTX_diagonal_list)]\n",
      "/Users/jor6523/miniconda3/envs/MultiSuSiE/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/jor6523/miniconda3/envs/MultiSuSiE/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "XTY_list = [geno.T.dot(y) for (geno, y) in zip(geno_list, y_list)]\n",
    "XTX_diagonal_list = [np.diagonal(geno.T.dot(geno)) for geno in geno_list]\n",
    "beta_hat_list = [XTY / XTX_diag for (XTY, XTX_diag) in zip(XTY_list, XTX_diagonal_list)]\n",
    "\n",
    "N_list = [geno.shape[0] for geno in geno_list]\n",
    "residuals_list = [np.expand_dims(y, 1) - (geno * beta) for (y, geno, beta) in zip(y_list, geno_list, beta_hat_list)]\n",
    "sum_of_squared_residuals_list = [np.sum(resid ** 2, axis = 0) for resid in residuals_list]\n",
    "se_list = [np.sqrt(ssr / ((N - 2) * XTX)) for (ssr, N, XTX) in zip(sum_of_squared_residuals_list, N_list, XTX_diagonal_list)]\n",
    "\n",
    "R_list = [np.corrcoef(geno, rowvar = False) for geno in geno_list]\n",
    "\n",
    "YTY_list = [y.dot(y) for y in y_list]\n",
    "varY_list = [np.var(y, ddof = 1) for y in y_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d505db-b5b9-4b0f-82ef-324e3c276638",
   "metadata": {},
   "source": [
    "# Demonstrate summary statistic based fine-mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72821e29-3152-4aab-aad1-c8ec08b121de",
   "metadata": {},
   "source": [
    "To run summary-statistic based multi-ancestry fine-mapping, we need five inputs for each population: GWAS variant effect sizes, GWAS variant standard errors, an LD matrix, the sample phenotype variance, and the GWAS sample size. Each of these inputs should be formatted as a list of numpy arrays (for the GWAS variant effect sizes, GWAS variant standard errors, and LD matrix) or a list of scalars(for the sample phenotype variance and GWAS sample size). The summary statistics we calculated above are already in this format.\n",
    "\n",
    "Now, to run MultiSuSiE, we just have to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "281e82bd-e361-48d8-82fc-6685c6aba730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "censored 15 variants in population 0\n",
      "censored 14 variants in population 1\n",
      "censored 16 variants in population 2\n"
     ]
    }
   ],
   "source": [
    "ss_fit = MultiSuSiE.multisusie_rss(\n",
    "    b_list = beta_hat_list,\n",
    "    s_list = se_list,\n",
    "    R_list = R_list,\n",
    "    varY_list = varY_list,\n",
    "    rho = np.array([[1, 0.75, 0.75], [0.75, 1, 0.75], [0.75, 0.75, 1]]),\n",
    "    population_sizes = N_list,\n",
    "    L = 10,\n",
    "    scaled_prior_variance = 0.2,\n",
    "    low_memory_mode = False,\n",
    "    mac_filter = 10,\n",
    "    maf_filter = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca09f5-d53a-44c6-913e-c24edd6f7635",
   "metadata": {},
   "source": [
    "Here, we've decreased the threshold for the MAC_filter argument from the default value due to our extremely small sample sizes. By examining the `pip` attribute of the object returned by `MultiSuSiE`, we can see that we've correctly assigned very high PIP to the 11th and 38th variants, and moderate PIP to the 4th variant, all of which we've assigned true causal effects in our simulations. By examining the `sets` attribute, we can see that the causal variant with lower PIP has been placed in a 95% credible set with only other variant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba567f-7ab5-4ac7-b67d-06bc4382fc98",
   "metadata": {},
   "source": [
    "# Show equivalence of individual and ss based methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f71f5-c432-45e2-b702-60f87e43f2b5",
   "metadata": {},
   "source": [
    "Next, we'll demonstrate that the individual and summary statistic based versions of MultiSuSiE give identical results. At the time when this tutorial was being written, some of the default parameters for `multisusie_rss` (the top-level summary-statistic based fine-mapping function) have not been implemented for `susie_multi` (the top-level individual-level based fine-mapping function), so we'll have to use some non-default parameters to get the same results for both functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfbafd13-9b89-4c4f-8c53-26068152e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_fit = MultiSuSiE.multisusie_rss(\n",
    "    b_list = beta_hat_list,\n",
    "    s_list = se_list,\n",
    "    R_list = R_list,\n",
    "    varY_list = varY_list,\n",
    "    rho = np.array([[1, 0.75, 0.75], [0.75, 1, 0.75], [0.75, 0.75, 1]]),\n",
    "    population_sizes = N_list,\n",
    "    L = 10,\n",
    "    scaled_prior_variance = 0.2,\n",
    "    low_memory_mode = False,\n",
    "    min_abs_corr = 0,\n",
    "    recover_R = False,\n",
    "    float_type = np.float64,\n",
    "    estimate_prior_method = 'EM',\n",
    "    pop_spec_effect_priors = False,\n",
    "    iter_before_zeroing_effects = 0,\n",
    "    mac_filter = 0,\n",
    "    maf_filter = 0\n",
    ")\n",
    "indiv_fit = MultiSuSiE.multisusie(\n",
    "    X_list = geno_list,\n",
    "    Y_list = y_list,\n",
    "    rho = np.array([[1, 0.75, 0.75], [0.75, 1, 0.75], [0.75, 0.75, 1]]),\n",
    "    L = 10,\n",
    "    scaled_prior_variance = 0.2,\n",
    "    standardize = False,\n",
    "    intercept = False,\n",
    "    float_dtype = np.float64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94540bb7-1f9c-472a-b5b9-73bb55f5f5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here, we can see that the maximum difference in PIP between the two methods is  2.7755575615628914e-15"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(\"Here, we can see that the maximum difference in PIP between the two methods is  {}\".format(np.max(np.abs(ss_fit.pip - indiv_fit.pip))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
